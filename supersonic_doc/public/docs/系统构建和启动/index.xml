<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>系统构建和启动 on SuperSonic</title>
    <link>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/</link>
    <description>Recent content in 系统构建和启动 on SuperSonic</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>环境依赖</title>
      <link>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/%E7%8E%AF%E5%A2%83%E4%BE%9D%E8%B5%96/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/%E7%8E%AF%E5%A2%83%E4%BE%9D%E8%B5%96/</guid>
      <description>Python 服务 (如果需要用到LLM的能力, 需要启动python服务)&#xA;Python版本: 3.9+ pip版本: 3.9+&#xA;其它需要用到的包(启动服务的时候, 会默认检测安装):&#xA;langchain==0.0.207 openai==0.27.4 fastapi==0.95.1&#xA;chromadb==0.3.21 tiktoken==0.3.3 uvicorn[standard]==0.21.1(windows: uvicorn==0.21.1)&#xA;pandas==1.5.3&#xA;注意事项:&#xA;前往supersonic/chat/core/src/main/python/llm/run_config.py配置LLM key 服务host、port指定： 在supersonic/chat/core/src/main/python/llm/run_config.py中修改 python、pip环境指定： pip路径：在supersonic-common.sh中修改&#xA;python路径：在supersonic-common.sh中修改 注意：0.7.4release版本：在supersonic/chat/core/src/main/python/bin/env.sh中修改&#xA;默认pip路径为/usr/local/bin/pip3，python路径为/usr/local/bin/python3, 若不在这个路径,需要在修改成自己的路径&#xA;Windows下需要将python和pip指令配置好环境变量&#xA;后端服务&#xA;JDK版本: 1.8+&#xA;前端服务&#xA;Node版本: 16+ pnpm</description>
    </item>
    <item>
      <title>构建和启动</title>
      <link>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/</guid>
      <description>Release包启动&#xA;下载最新release包 sh bin/supersonic-daemon.sh start http://localhost:9080 IDE启动(后端直接访问前端资源的方式) sh assembly/bin/supersonic-build.sh 执行构建 IDE本地启动Java类StandaloneLauncher http://localhost:9080 IDE启动(前后端分开启动的方式) IDE本地启动Java类StandaloneLauncher 进入webapp目录，执行sh start-fe-dev.sh直接启动前端服务 http://localhost:9000 注意这里是9000端口 Source Code启动 sh assembly/bin/supersonic-build.sh 执行构建 sh assembly/bin/supersonic-daemon.sh start http://localhost:9080 PS:&#xA;Windows环境均有提供对应的bat脚本, 执行即可&#xA;系统目前支持两种访问LLM和向量库的方式:&#xA;a. Java服务通过langchain4j直接访问LLM的方式, 只需要按如上方式启动服务即可&#xA;b. 另起Python服务的方式来访问LLM, 执行sh assembly/bin/supersonic-daemon.sh start pyllm即可, 这条命令会同时启动Python服务和Java服务, 只不过是通过Python服务 来访问LLM&#xA;Java和Python两种访问LLM的相关配置均可参考LLM与text2sql配置&#xA;执行构建和启动之前, 请先查看环境依赖&#xA;Ubuntu环境, 启动方式同上, 若出现报错, 可尝试https://support.huaweicloud.com/intl/zh-cn/deployman_faq/deployman_faq_1016.html&#xA;启动之后, 可以到logs目录下查看日志, llm解析服务相关日志可以到llm/logs目录下查看&#xA;数据库表结构可直接参考launcher/standalone下的sql脚本, h2数据库schema-h2.sql, data-h2.sql, mysql数据库schema-mysql.sql, data-mysql.sql, 这两个脚本均为最新表结构, 每次发版更新的sql会放到sql-update.sql (第一次启动不需要管sql-update.sql, 只是已经在mysql上跑过, 如果不想重新建表导数据, 就需要对照sql-update.sql中的sql执行日期来进行表结构更新)&#xA;系统默认对h2数据库支持样例数据, 若需要基于本地mysql查看样例数据, 可执行schema-mysql.sql来创建最新表结构, 并执行data-mysql.sql把样例数据写入mysql, 之后系统在启动的时候会自动把系统元数据和会话数据写入mysql表,系统启动成功后可在页面看到样例数据, 详细可参考DemoLoader。若需要从h2切换至mysql, 按如下正常配置即可</description>
    </item>
    <item>
      <title>LLM与text2sql配置</title>
      <link>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/llm%E4%B8%8Etext2sql%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://supersonicbi.github.io/docs/%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E5%92%8C%E5%90%AF%E5%8A%A8/llm%E4%B8%8Etext2sql%E9%85%8D%E7%BD%AE/</guid>
      <description>语言模型的使用是SuperSonic的重要一环。能显著增强对用户的问题的理解能力，是通过对话形式与用户交互的基石之一。在本项目中对语言模型能力的应用主要在 LLM 和 Embedding 两方面, 且支持Java和Python两种访问语言模型的方式, 下面分别介绍这两种访问方式的配置。&#xA;JavaLLMProxy&#xD;#&#xD;服务默认启动方式就为Java访问语言模型的方式, 语言模型相关配置可直接通过YAML文件来配置, 目前在配置中支持配置访问open-ai的key和LLM模型的名称 PythonLLMProxy&#xD;#&#xD;Python访问LLM的方式需要通过sh assembly/bin/supersonic-daemon.sh start pyllm来启动Python服务, 该命令同时也会启动Java服务, 但通过Python服务来访问LLM。 Python服务默认使用的模型中，LLM选用闭源模型 gpt-3.5-turbo-16k，Embedding模型选用开源模型 GanymedeNil/text2vec-large-chinese。用户可以根据自己实际需求进行配置更改。&#xA;配置方式 LLM模型的配置&#xD;#&#xD;LLM模型相关的配置，在 supersonic/chat/core/src/main/python/config/run_config.ini 进行配置。 LLM默认采用OpenAI的闭源模型 gpt-3.5-turbo-16k，用户可以根据自己的实际需要选择LLM模型的提供方，例如Azure、文心一言等。通过[LLMProvider]下的LLM_PROVIDER_NAME 变量进行配置。需要注意的是，现阶段支持配置的模型提供方必须能够被langchain所支持，提供方的名字可以在langchain文档中查询。 LLM的相关变量在[LLMModel]下进行配置，例如openAI的模型，需要提供 MODEL_NAME、OPENAI_API_KEY、TEMPERATURE 等参数配置。不同的LLM提供方需要的配置各不相同，用户可以根据实际情况配置相关变量。 Embedding模型配置&#xD;#&#xD;Embedding模型默认采用开源模型 GanymedeNil/text2vec-large-chinese。用户可以根据实际需要配置适合的Embedding模型；通过[Text2Vec]下 HF_TEXT2VEC_MODEL_NAME 变量进行配置，为了使用方便采用托管在HuggingFace的源，初次启动时自动下载模型文件。 LLM与embedding配置 FAQ&#xD;#&#xD;可以用开源的LLM模型替代OpenAI的GPT模型吗？ 暂时不能。我们测试过大部分主流的开源LLM，在实际使用中，在本项目需要LLM提供的逻辑推理和代码生成场景上，开源模型还不能满足需求。 我们会持续跟进开源LLM的最新进展，在有满足要求的开源LLM后，在项目中集成私有化部署开源LLM的能力。 可以用国产的闭源模型替代OpenAI的GPT模型吗？ 据部分用户反馈，在他们的场景下文心一言、混元等国产闭源模型的效果与GPT3.5差距不大；整体而言GPT3.5及GPT4适用的场景会更广泛一些。用户可以在自己的场景下修改LLM的相应配置，试一试实际效果。 GPT4、GPT3.5、GPT3.5-16k 这几个模型用哪个比较好？ GPT3.5、GPT3.5-16k 均能基本满足要求，但会有输出结果不稳定的情况；GPT3.5的token长度限制为4k，在现有CoT策略下，容易出现超过长度限制的情况。 GPT4的输出更稳定，但费用成本远超GPT3.5，可以根据实际使用场景进行选择。 Embedding模型用其他的可以吗？ 可以。可以以该项目text2vec的榜单作为参考，然后在HuggingFace找到对应模型的model card，修改HF_TEXT2VEC_MODEL_NAME变量的取值。 启动时，首次下载Embedding模型需要会链接HuggingFace的源进行下载，如果网络不通怎么办？ 可以到HuggingFace的官网找到对应的model card，然后将模型下载到本地。在supersonic/chat/core/src/main/python/config/run_config.ini 中将HF_TEXT2VEC_MODEL_NAME变量配置为模型所在的绝对路径。 LLM在text2sql中的应用&#xD;#&#xD;text2sql的功能实现，高度依赖对LLM的应用。通过LLM生成SQL的过程中，利用小样本(few-shots-examples)通过思维链(chain-of-thoughts)的方式对LLM in-context-learning的能力进行引导，对于生成较为稳定且符合下游语法解析规则的SQL非常重要。用户可以根据自身需要，对样本池及样本的数量进行配置，使其更加符合自身业务特点。&#xA;text2sql运行中更新配置的脚本&#xD;#&#xD;如果在启动项目后，用户需要对text2sql功能的相关配置进行调试，可以在修改相关配置文件后，通过以下2种方式让配置在项目运行中让配置生效。 执行 supersonic-daemon.sh reload llmparser 执行 python examples_reload_run.</description>
    </item>
  </channel>
</rss>
